{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP: Review Summary, Sentiment Analysis\n",
    "Reviews Summarizer on reviews, where is review summarizer lecture? Tips and recommendations here. SUMY  \n",
    "- (done) Clean contractions, Lemmatize??, Remove Stop words (think specific to reviewing airbnb)\n",
    "- parts of speech (removing pronouns, San Francisco)\n",
    "- Tokenize\n",
    "- Vectorize\n",
    "- StandardScale\n",
    "- Dim Reduction\n",
    "- Topic Model\n",
    "- Clustering on reviews: try all the methods, Kmeans, DBScan, .....\n",
    "- Sumy LSA\n",
    "- Gensim summarizer()TextBlob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:42:23.173036Z",
     "start_time": "2018-09-05T00:42:23.137478Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import timeit\n",
    "from collections import Counter\n",
    "\n",
    "# Graphics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg'\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.2)\n",
    "plt.style.use('seaborn')\n",
    "# from mlxtend.plotting import plot_decision_regions\n",
    "# from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:42:23.933316Z",
     "start_time": "2018-09-05T00:42:23.927938Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from operator import itemgetter\n",
    "import contractions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:42:24.686873Z",
     "start_time": "2018-09-05T00:42:24.682669Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %run '/Users/bellepeng/Desktop/Metis/Projects/Project_AirBNB/notebooks/helper_functions.py' \n",
    "os.chdir('/Users/bellepeng/Desktop/Metis/Projects/Project_AirBNB/notebooks')\n",
    "import helper_functions\n",
    "from helper_functions import clean_dolla, plot_bar, cluster_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:42:25.615728Z",
     "start_time": "2018-09-05T00:42:25.573152Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6633, 95)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>weekly_price</th>\n",
       "      <th>...</th>\n",
       "      <th>neighborhood_Potrero Hill</th>\n",
       "      <th>neighborhood_Presidio Heights</th>\n",
       "      <th>neighborhood_Russian Hill</th>\n",
       "      <th>neighborhood_Seacliff</th>\n",
       "      <th>neighborhood_South of Market</th>\n",
       "      <th>neighborhood_Twin Peaks</th>\n",
       "      <th>neighborhood_Visitacion Valley</th>\n",
       "      <th>neighborhood_West of Twin Peaks</th>\n",
       "      <th>neighborhood_Western Addition</th>\n",
       "      <th>host_in_same_neighborhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_listings_count  host_total_listings_count  \\\n",
       "0                  1                    1                          1   \n",
       "1                  0                    2                          2   \n",
       "2                  0                   10                         10   \n",
       "3                  0                   10                         10   \n",
       "4                  0                    2                          2   \n",
       "\n",
       "   host_has_profile_pic  host_identity_verified  bathrooms  bedrooms  beds  \\\n",
       "0                     1                       1        1.0       1.0   2.0   \n",
       "1                     1                       1        1.0       2.0   3.0   \n",
       "2                     1                       1        4.0       1.0   1.0   \n",
       "3                     1                       1        4.0       1.0   1.0   \n",
       "4                     1                       1        1.5       2.0   2.0   \n",
       "\n",
       "   price  weekly_price            ...              neighborhood_Potrero Hill  \\\n",
       "0  170.0        1120.0            ...                                      0   \n",
       "1  235.0        1600.0            ...                                      0   \n",
       "2   65.0         485.0            ...                                      0   \n",
       "3   65.0         490.0            ...                                      0   \n",
       "4  675.0           0.0            ...                                      0   \n",
       "\n",
       "   neighborhood_Presidio Heights  neighborhood_Russian Hill  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   neighborhood_Seacliff  neighborhood_South of Market  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "\n",
       "   neighborhood_Twin Peaks  neighborhood_Visitacion Valley  \\\n",
       "0                        0                               0   \n",
       "1                        0                               0   \n",
       "2                        0                               0   \n",
       "3                        0                               0   \n",
       "4                        0                               0   \n",
       "\n",
       "   neighborhood_West of Twin Peaks  neighborhood_Western Addition  \\\n",
       "0                                0                              1   \n",
       "1                                0                              0   \n",
       "2                                0                              0   \n",
       "3                                0                              0   \n",
       "4                                0                              1   \n",
       "\n",
       "   host_in_same_neighborhood  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/Users/bellepeng/Desktop/Metis/Projects/Project_AirBNB/data')\n",
    "with open('listings_sf_cleaned.pkl', 'rb') as file:\n",
    "    listings = pickle.load(file)\n",
    "\n",
    "print(listings.shape)\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:03:55.142078Z",
     "start_time": "2018-09-05T01:03:53.346271Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278884, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>958</td>\n",
       "      <td>5977</td>\n",
       "      <td>2009-07-23</td>\n",
       "      <td>Our experience was, without a doubt, a five st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>958</td>\n",
       "      <td>6660</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>Returning to San Francisco is a rejuvenating t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>11519</td>\n",
       "      <td>2009-09-27</td>\n",
       "      <td>We were very pleased with the accommodations a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>958</td>\n",
       "      <td>16282</td>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>We highly recommend this accomodation and agre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>958</td>\n",
       "      <td>26008</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>Holly's place was great. It was exactly what I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id     id        date  \\\n",
       "0         958   5977  2009-07-23   \n",
       "1         958   6660  2009-08-03   \n",
       "2         958  11519  2009-09-27   \n",
       "3         958  16282  2009-11-05   \n",
       "4         958  26008  2010-02-13   \n",
       "\n",
       "                                            comments  \n",
       "0  Our experience was, without a doubt, a five st...  \n",
       "1  Returning to San Francisco is a rejuvenating t...  \n",
       "2  We were very pleased with the accommodations a...  \n",
       "3  We highly recommend this accomodation and agre...  \n",
       "4  Holly's place was great. It was exactly what I...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews=pd.read_csv('SF/201808/reviews_201808.csv')\n",
    "reviews.columns\n",
    "drop_list = ['reviewer_id', 'reviewer_name']\n",
    "print(reviews.shape)\n",
    "[reviews.drop(x, inplace=True, axis=1) for x in drop_list]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:50:58.032474Z",
     "start_time": "2018-09-05T00:50:58.026284Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I had great time staying at Brenda's house. She is an exellent host, very friendly and helpful. The place was beautiful and the location perfect. I can really recommend staying with Brenda while you're in San Francisco. I only had very few days in SF but I would like to come back and stay at Brenda's place again. Thanks for everything!!\n",
      "\n",
      "I had great time staying at Brenda's house. She is an exellent host, very friendly and helpful. The place was beautiful and the location perfect. I can really recommend staying with Brenda while you are in San Francisco. I only had very few days in SF but I would like to come back and stay at Brenda's place again. Thanks for everything!!\n"
     ]
    }
   ],
   "source": [
    "ix=2000\n",
    "print(reviews['comments'][ix])\n",
    "print()\n",
    "print(contractions.fix(reviews['comments'][ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T00:57:22.556906Z",
     "start_time": "2018-09-05T00:57:22.544193Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>958</td>\n",
       "      <td>5977</td>\n",
       "      <td>2009-07-23</td>\n",
       "      <td>Our experience was, without a doubt, a five st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>958</td>\n",
       "      <td>6660</td>\n",
       "      <td>2009-08-03</td>\n",
       "      <td>Returning to San Francisco is a rejuvenating t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>958</td>\n",
       "      <td>11519</td>\n",
       "      <td>2009-09-27</td>\n",
       "      <td>We were very pleased with the accommodations a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>958</td>\n",
       "      <td>16282</td>\n",
       "      <td>2009-11-05</td>\n",
       "      <td>We highly recommend this accomodation and agre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>958</td>\n",
       "      <td>26008</td>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>Holly's place was great. It was exactly what I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id     id        date  \\\n",
       "0         958   5977  2009-07-23   \n",
       "1         958   6660  2009-08-03   \n",
       "2         958  11519  2009-09-27   \n",
       "3         958  16282  2009-11-05   \n",
       "4         958  26008  2010-02-13   \n",
       "\n",
       "                                            comments  \n",
       "0  Our experience was, without a doubt, a five st...  \n",
       "1  Returning to San Francisco is a rejuvenating t...  \n",
       "2  We were very pleased with the accommodations a...  \n",
       "3  We highly recommend this accomodation and agre...  \n",
       "4  Holly's place was great. It was exactly what I...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:06:37.942895Z",
     "start_time": "2018-09-05T01:06:37.937040Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if (type(text)==float): # For missings\n",
    "        return \"\"\n",
    "    else:\n",
    "        text = contractions.fix(text)\n",
    "        lemmatize = WordNetLemmatizer()\n",
    "        tokens = word_tokenize(text)\n",
    "        clean_text = [lemmatize.lemmatize(token.lower().strip(), pos='v') for token in tokens]\n",
    "        clean_text = [x for x in clean_text if x not in stop]\n",
    "        return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:20:31.964095Z",
     "start_time": "2018-09-05T01:06:51.260327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['experience without doubt five star experience holly husband david consummate host ; friendly accomodating still honor privacy apartment charm layout full view access home garden location perfect full engagement city ; close mass transit walk proximity haight mission castro golden gate park wait next visit ted karen wingerd']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_cleaned = [clean_text(r) for r in reviews['comments']]\n",
    "print(len(reviews_cleaned))\n",
    "reviews_cleaned[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:31:23.477185Z",
     "start_time": "2018-09-05T01:31:23.004767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bellepeng/Desktop/Metis/Projects/Project_AirBNB/data\r\n"
     ]
    }
   ],
   "source": [
    "# !pwd\n",
    "# import pickle\n",
    "# with open('reviews_cleaned.pkl', 'wb') as file:\n",
    "#     pickle.dump(reviews_cleaned, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:33:23.478986Z",
     "start_time": "2018-09-05T01:33:23.466684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "189\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "stop = stopwords.words('english')\n",
    "print(len(stop))\n",
    "punctuations=['.', ',', '(', ')', \"!\", \"?\", \"'\", '\"', \"<\", \">\"]\n",
    "more=[\"/n\", \"/t\", \"'s\"]\n",
    "stop += punctuations\n",
    "print(len(stop))\n",
    "stop += more\n",
    "print(len(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:37:01.848376Z",
     "start_time": "2018-09-05T01:35:48.963125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278884\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenized = [word_tokenize(i) for i in reviews_cleaned]\n",
    "print(len(tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:43:02.959766Z",
     "start_time": "2018-09-05T01:43:02.952400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-05T01:43:20.184183Z",
     "start_time": "2018-09-05T01:43:16.788457Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-9a60181459d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# tfidf = [tfidf_vectorizer.fit_transform(i) for i in tokenized]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-9a60181459d9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# tfidf = [tfidf_vectorizer.fit_transform(i) for i in tokenized]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    812\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2), stop_words=stop, lowercase=True)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words=stop, lowercase=True)\n",
    "\n",
    "cv = [count_vectorizer.fit_transform(i) for i in tokenized if len(i)>0]\n",
    "# tfidf = [tfidf_vectorizer.fit_transform(i) for i in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScale\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anacoda)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
